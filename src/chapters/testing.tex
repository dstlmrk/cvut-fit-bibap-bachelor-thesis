\chapter{Testování}

% IDEA: rozepsat se s rozdelenim dalsich testu

Jednou z nejdůležitejších součástí vývoje je testování. Pomáhá zkoumat funkčnost softwaru a v případě bezchybného
a úplného testování zajišťuje, že výsledná aplikace neobsahuje chyby a má požadované vlastnosti.
Testování se často provádí ve více iteracích, například pravidelně před vydáním nové verze softwaru.
Součástí testování je pak především reportování nalezených chyb.

Testy se dělí na tzv. black-box a white-box testy. Při testování černé skřínky nemáme informace o vnitřní podobě a porovnáváme
pouze správnost výstupních dat po zadání vstupních. Do testovaného subjektu se nelze podívat, vidíme jen to, jak se chová navenek.
Důvodem tohoto typu testování je analyzovat software z pohledu uživatele.
Na opačné straně se při znalosti implementace používá testování bílé skřínky. Sice tato metoda zastiňuje pohled uživatele,
ale tester je schopen lépe určit, kde hledat případné chyby. Při~částečné znalosti softwaru se ještě používá pojem testování šedé skřínky (gray-box).
Neznáme například přesnou podobu zdrojového kódu, ale jen algoritmus použitý v aplikaci. 

Testy se také dělí na automatizované a manuální. Méně nákladnou a rychlejší cestou je zpravidla automatizované testování,
kdy se automaticky spouští velké množství testů, často i s velkým množstvím vstupních dat. Tyto testy se používají v místech,
kde dochází k opakování stejného nebo velmi podobného scénáře. Ne vždy se ale používá pouze automatizované testování.
Když test vyžaduje lidský úsudek, rozdílné přístupy nebo jej není nutné pravidelně opakovat, používá se manuální testování či kombinace obojího.

\section{Testování Catchera}

Testování softwaru je stále velmi podceňovaný obor a často je tato fáze vývoje odsunuta na druhou kolej nebo zcela vynechána.
Kromě toho, že psaní testů se ukázalo jako nejrychlejší způsob odhalování chyb, bylo pak ještě více překvapující, že při~použití
techniky TDD\footnote{Test-driven development - technika, kdy se testy píší ještě před samotným vývojem.} se znatelně zefektivnil
vývoj. Už~při~psaní zdrojového kódu jsem tak mohl jednoduše spouštět již vytvořené testy a znát jejich stav.
Díky specifickému popisu získání a~manipulace se zdroji v architektuře REST jsem většinu testů podřídil tomuto rozdělení a prováděl
jsem tzv. testování funkcionalit -- z pohledu uživatele, ověřování úzce zaměřených scénářů.

V Pythonu se nejrozšířenější framework pro automatizované testování jmenuje Unittest~\cite{python_unittest}. Já jsem však využil testovací nástroj, jenž přímo
poskytuje webový framework Falcon. Je potřeba zmínit, že tento nástroj většinu metod dědí od~základního Unittestu a~jeho možnosti pouze
rozšiřuje pro~lepší a~rychlejší testování REST API.

Automatizovanými testy jsou v~Catcheru pokryty všechny zdroje s~jejich metodami (celkem jich je 66). Typicky jsou testy po~několika sdružovány do~jedné třídy,
ve~které je možnost vytvořit specifické testovací prostředí. V knihovně \texttt{unittest} jsou pro tyto účely často používány metody \pythoninline{setUp()} a~\pythoninline{tearDown()},
které jsou volány před, respektive po každém testu. Důsledek tohoto chování je zajištění velmi důležitého aspektu v testování -- nezávislosti testů.
Bez něj by mohly testy pracovat nad stejnou množinou dat a navzájem si \uv{kazit} výsledky.
Nejčastější podoba testů pro~Catchera je vidět v~následující velmi zjednodušené ukázce kódu: 

\begin{python}
class TestClubs(falcon.testing.TestBase):

    def setUp(self):
      '''Spustí se před každým testem,
      zpravidla naplní testovací databázi daty.'''

    def tearDown(self):
      '''Spustí se po každém testu,
      zpravidla vyčistí testovací databázi.'''

    def testGet(self):
      '''Testuje požadavek GET - získá kolekci všech oddílů.'''     
      response = self.simulate_request('GET', '/api/clubs')
      self.assertEqual(self.srmock.status, HTTP_200)

    def testPost(self):
      '''Testuje požadavek POST - vytvoří nový oddíl.'''
      response = self.simulate_request('POST', '/api/clubs', body)
      self.assertEqual(self.srmock.status, HTTP_201)
\end{python}

Kromě porovnávání návratových HTTP kódů se v mých testech zkoumá podoba a obsah návratových dat, správné vyhazování výjimek
nebo stav testovací databáze před a po volání metod.